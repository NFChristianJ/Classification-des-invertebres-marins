{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7f9d9c-907b-485a-9130-a5ec190b33a4",
   "metadata": {},
   "source": [
    "# Importation des bibliotheques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c8a6ab-c069-4964-9b71-2922fbf2a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from timm import create_model\n",
    "import time \n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718c8435-26fe-49bb-973a-d9d04e4695cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images par classe dans train_data :\n"
     ]
    }
   ],
   "source": [
    "# Chemin du dossier train_data\n",
    "dossier_train_data = r\"C:\\Users\\Christian\\Desktop\\UE Projet\\Dataset\\train_data\"\n",
    "\n",
    "# Dictionnaire pour stocker le nombre d'images par classe\n",
    "nombre_images_par_classe = defaultdict(int)\n",
    "\n",
    "# Parcourir tous les fichiers dans le dossier train_data\n",
    "for file_name in os.listdir(dossier_train_data):\n",
    "    \"\"\"Les fichiers sont dans un dossiers train data déja prétraités. Nous allons extraire le nombre qui se trouve dans la structure du nom de chaque fichiers et conserver le nom de l'image qui represente la classe\"\"\"\n",
    "    # Utiliser une expression régulière pour extraire la partie avant le nombre\n",
    "    match = re.match(r\"^(.*?)(\\d+)\\.jpeg$\", file_name)\n",
    "    if match:\n",
    "        class_name = match.group(1)\n",
    "        nombre_images_par_classe[class_name] += 1\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Nombre d'images par classe dans train_data :\")\n",
    "for classe, nombre in nombre_images_par_classe.items():\n",
    "    print(f\"{classe} : {nombre}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e226c2d6-6a9a-4e3c-b47a-e864cc489f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Ici on va stocker les images par classes pour voir la classe a laquelle chaque image correspond\"\"\"\n",
    "# Dictionnaire pour stocker les fichiers par classe\n",
    "fichiers_par_classe = {}\n",
    "\n",
    "# Parcourir tous les fichiers dans le dossier train_data\n",
    "for file_name in os.listdir(dossier_train_data):\n",
    "    # Utiliser une expression régulière pour extraire la classe\n",
    "    match = re.match(r\"^(.*?)(\\d+)\\.jpeg$\", file_name)\n",
    "    if match:\n",
    "        class_name = match.group(1)\n",
    "        if class_name not in fichiers_par_classe:\n",
    "            fichiers_par_classe[class_name] = []\n",
    "        fichiers_par_classe[class_name].append(file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f63c43-45cc-4903-b231-5be65678ddb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ici on affiche juste les images par classe.\n",
    "fichiers_par_classe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d50e56e-e1c6-4b93-9029-314be1325132",
   "metadata": {},
   "source": [
    "### Ici on va entrainer notre modele sur notre dataset d'entrainement complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4762f1f-92c3-4a83-8ef9-720e631bbd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images réorganisées en sous-dossiers par classe.\n"
     ]
    }
   ],
   "source": [
    "# Chemin du dossier train_data\n",
    "dossier_train_data = r\"C:\\Users\\Christian\\Desktop\\UE Projet\\Dataset\\train_data\"\n",
    "\n",
    "# Organiser les images en sous-dossiers\n",
    "for file_name in os.listdir(dossier_train_data):\n",
    "    # Utiliser une expression régulière pour extraire la classe\n",
    "    match = re.match(r\"^(.*?)(\\d+)\\.jpeg$\", file_name)\n",
    "    if match:\n",
    "        class_name = match.group(1)\n",
    "        class_dir = os.path.join(dossier_train_data, class_name)\n",
    "        \n",
    "        # Créer le sous-dossier si nécessaire\n",
    "        if not os.path.exists(class_dir):\n",
    "            os.makedirs(class_dir)\n",
    "        \n",
    "        # Déplacer l'image dans le sous-dossier\n",
    "        src_path = os.path.join(dossier_train_data, file_name)\n",
    "        dst_path = os.path.join(class_dir, file_name)\n",
    "        shutil.move(src_path, dst_path)\n",
    "\n",
    "print(\"Images réorganisées en sous-dossiers par classe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebd7c92-c49d-4f00-a91c-beb6e4e54259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3111 files belonging to 137 classes.\n",
      "(32, 128, 128, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "# Les données d'entrainement et de test\n",
    "dossier_train = r\"C:\\Users\\Christian\\Desktop\\UE Projet\\Dataset\\train_data\"\n",
    "\n",
    "# Définitions des paramètres pour la taille des images et le nombres d'images traités par lot\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Créer un dataset à partir des fichiers d'entraînement\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=dossier_train,\n",
    "    labels='inferred', # Pour specifier que chaque images de chaque sous repertoires appartient uniquement a cette classe\n",
    "    label_mode='int', # Encodage en entier pour convertir les labels(classes/sous repertoire) en entier afin de faciliter l'entrainement\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Normaliser les images\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "# Appliquer la normalisation aux datasets\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# Afficher la structure des datasets\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(images.shape)  # Afficher la forme des tenseurs d'images\n",
    "    print(labels.shape)  # Afficher la forme des tenseurs de labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1a4ff-bc1e-4f78-9138-f366c66b9a43",
   "metadata": {},
   "source": [
    "### Application de la data augmentation\n",
    "\n",
    "Grace a cette technique, lors de l'entrainement du modele sur 10 epoques, le modele aura un equivalent d'environ 30000 images dans sa base d'entrainement. Le principe est le suivant: Lors de l'entrainement du modele sur chaque époques, chaque image recevra les transformations suivante avant d'etre reconnu par le modele comme element d'une classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c99d9f8a-2b9f-4280-a4f9-a01d47fe822c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3111 images belonging to 137 classes.\n",
      "(32, 128, 128, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "# Chemin des dossiers train et test\n",
    "dossier_train = r\"C:\\Users\\Christian\\Desktop\\UE Projet\\Dataset\\train_data\"\n",
    "\n",
    "# Créer un générateur d'images avec augmentation pour l'entraînement\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Appliquer le générateur aux données d'entraînement\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=dossier_train,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse'  # Utiliser 'sparse' pour les étiquettes entières\n",
    ")\n",
    "\n",
    "# Afficher la structure des datasets\n",
    "for images, labels in train_generator:\n",
    "    print(images.shape)  # Afficher la forme des tenseurs d'images\n",
    "    print(labels.shape)  # Afficher la forme des tenseurs de labels\n",
    "    break  # Pour éviter d'afficher toutes les images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8208ee-2128-47cf-8368-a3ca9b0b9670",
   "metadata": {},
   "source": [
    "### Vérifieons le contenu du répertoire train avant son passage dans le modele et voyons a quoi correspond chaque classe de l'ensemble d'entrainement par rapport aux classes de depart. On va verifier cela avec les indices car plus haut nous avons utiliser un encodage pour encoder nos differentes classes en valeurs entieres (le target encoding) pour faciliter le passage dans le modele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13efecda-0d39-401e-8e91-cb242a834df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu du répertoire 'train_data' :\n",
      "Actiniaria_\n",
      "Actinoptilum_molle_\n",
      "Actinoscyphia_plebeia_\n",
      "Actinostola_capensis_\n",
      "Aequorea_spp_\n",
      "Africolaria_rutila_\n",
      "Alcyonacea_\n",
      "Amalda_bullioides_\n",
      "Anthoptilum_grandiflorum_\n",
      "Aphelodoris_sp__\n",
      "Aphrodita_alta_\n",
      "Aristeus_varidens_\n",
      "Armina_sp__\n",
      "Ascidiacea_\n",
      "Astropecten_irregularis_pontoporeus_\n",
      "Athleta_abyssicola_\n",
      "Athleta_lutosa_\n",
      "Bolocera_kerguelensis_\n",
      "Brissopsis_lyrifera_capensis_\n",
      "Bryozoa_\n",
      "Cavernularia_spp_\n",
      "Cephalodiscus_gilchristi_\n",
      "Ceramaster_patagonicus_euryplax_\n",
      "Charonia_lampas_\n",
      "Cheilostomatida_\n",
      "Cheiraster_hirsutus_\n",
      "Chondraster_elattosis_\n",
      "Chrysaora_fulgida_\n",
      "Chrysaora_spp_\n",
      "Comanthus_wahlbergii_\n",
      "Comitas_saldanhae_\n",
      "Comitas_stolida_\n",
      "Cosmasterias_felipes_\n",
      "Crossaster_penicillatus_\n",
      "Cypraeovula_iutsui_\n",
      "Diplopteraster_multipes_\n",
      "Dipsacaster_sladeni_capensis_\n",
      "Echinus_gilchristi_\n",
      "Eleutherobia_variable_\n",
      "Euspira_napus_\n",
      "Exodromidia_spinosa_\n",
      "Exodromidia_spinosissima_\n",
      "Flabellum_(Ulocyathus)_messum_\n",
      "Funchalia_woodwardi_\n",
      "Fusinus_africanae_\n",
      "Fusinus_hayesi_\n",
      "Fusitriton_magellanicus_\n",
      "Fusivoluta_pyrrhostoma_\n",
      "Glyphocrangon_spp_\n",
      "Goneplax_clevai_\n",
      "Granulifusus_rubrolineatus_\n",
      "Gynandrocarpa_placenta_\n",
      "Halcurias_capensis_\n",
      "Haliporoides_triarthrus_\n",
      "Hemiocnus_insolens_\n",
      "Henricia_abyssalis_\n",
      "Hermit_crab_\n",
      "Hippasteria_phrygiana_\n",
      "Holothuroidea_\n",
      "Hydrozoa_spp_\n",
      "Inachidae_\n",
      "Isididae_\n",
      "Isopods_\n",
      "Kaloplocamus_ramosus_\n",
      "Lamellaria_Coriocella_spp_\n",
      "Limopsis_chuni_\n",
      "Lithodes_ferox_\n",
      "Lophaster_quadrispinus_\n",
      "Luidia_sarsii_africana_\n",
      "Marginella_musica_\n",
      "Marthasterias_africana_\n",
      "Mediaster_bairdi_capensis_\n",
      "Merhippolyte_agulhasensis_\n",
      "Miersiograpsus_kingsleyi_\n",
      "Munida_benguela_\n",
      "Mursia_cristiata_\n",
      "Mycale_anisochela_\n",
      "Nassarius speciosus_\n",
      "Nassarius_vinctus_\n",
      "Neolithodes_asperrimus_\n",
      "Neopilumnoplax_heterochir_\n",
      "Neptuneopsis_gilchristi_\n",
      "Nudibranchia_\n",
      "Ophiomyxa_vivipara_capensis_\n",
      "Ophiothrix_aristulata_\n",
      "Ophiothrix_fragilis_\n",
      "Ophiothrix_spp_\n",
      "Ophiura_costata_costata_\n",
      "Ophiura_trimeni_\n",
      "Pagurus_cuanensis_\n",
      "Parapagurus_bouvieri_\n",
      "Pasiphaea_sp._1_\n",
      "Pasiphaea_sp._2_\n",
      "Pecten_sulcicostatus_\n",
      "Pelagia_noctiluca_\n",
      "Perissasterias_polyacantha_\n",
      "Philine_aperta_\n",
      "Philinopsis_capensis_\n",
      "Phormosoma_placenta_africana_\n",
      "Plesionika_martia_\n",
      "Pleurobranchaea_bubala_\n",
      "Polychaete_tubes_(only)_\n",
      "Polychaete_worms_\n",
      "Polyechinus_agulhensis_\n",
      "Poraniopsis_echinaster_\n",
      "Porifera_\n",
      "Prawns_\n",
      "Projasus_parkeri_\n",
      "Pseudarchaster_brachyactis_\n",
      "Pseudarchaster_tessellatus_\n",
      "Pseudodromia_rotunda_\n",
      "Pseudodromia_spp__\n",
      "Pseudostichopus_langeae_\n",
      "Psilaster_acuminatus_\n",
      "Pteraster_capensis_\n",
      "Pterygosquilla_capensis_\n",
      "Pycnogonid_spp__\n",
      "Pyromaia_tuberculata_\n",
      "Rochinia_hertwigi_\n",
      "Rossella_antarctica_\n",
      "Salpa_spp__\n",
      "Scaphander_punctostriatus_\n",
      "Scleractinia_\n",
      "Sclerasterias_spp_\n",
      "Seafan_\n",
      "Solenocera_africana_\n",
      "Spatangus_capensis_\n",
      "Stereomastis_sculpta_\n",
      "Stylasteridae_\n",
      "Suberites_dandelenae_\n",
      "Sympagurus_dimorphus_\n",
      "Synallactes_viridilimus_\n",
      "Terebratulina_sp__\n",
      "Toraster_tuberculatus_\n",
      "Triviella_spp__\n",
      "Turritella_declivis_\n",
      "Vitjazmaia_latidactyla_\n"
     ]
    }
   ],
   "source": [
    "# Chemin du dossier d'entrainement\n",
    "dossier_train = r\"C:\\Users\\Christian\\Desktop\\UE Projet\\Dataset\\train_data\"\n",
    "# Affichage des classes\n",
    "print(\"Contenu du répertoire 'train_data' :\")\n",
    "for file_name in os.listdir(dossier_train):\n",
    "    print(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21d6c028-9059-462d-bc59-58519fe9f3d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes et indices correspondants :\n",
      "Indice 0 : Actiniaria_\n",
      "Indice 1 : Actinoptilum_molle_\n",
      "Indice 2 : Actinoscyphia_plebeia_\n",
      "Indice 3 : Actinostola_capensis_\n",
      "Indice 4 : Aequorea_spp_\n",
      "Indice 5 : Africolaria_rutila_\n",
      "Indice 6 : Alcyonacea_\n",
      "Indice 7 : Amalda_bullioides_\n",
      "Indice 8 : Anthoptilum_grandiflorum_\n",
      "Indice 9 : Aphelodoris_sp__\n",
      "Indice 10 : Aphrodita_alta_\n",
      "Indice 11 : Aristeus_varidens_\n",
      "Indice 12 : Armina_sp__\n",
      "Indice 13 : Ascidiacea_\n",
      "Indice 14 : Astropecten_irregularis_pontoporeus_\n",
      "Indice 15 : Athleta_abyssicola_\n",
      "Indice 16 : Athleta_lutosa_\n",
      "Indice 17 : Bolocera_kerguelensis_\n",
      "Indice 18 : Brissopsis_lyrifera_capensis_\n",
      "Indice 19 : Bryozoa_\n",
      "Indice 20 : Cavernularia_spp_\n",
      "Indice 21 : Cephalodiscus_gilchristi_\n",
      "Indice 22 : Ceramaster_patagonicus_euryplax_\n",
      "Indice 23 : Charonia_lampas_\n",
      "Indice 24 : Cheilostomatida_\n",
      "Indice 25 : Cheiraster_hirsutus_\n",
      "Indice 26 : Chondraster_elattosis_\n",
      "Indice 27 : Chrysaora_fulgida_\n",
      "Indice 28 : Chrysaora_spp_\n",
      "Indice 29 : Comanthus_wahlbergii_\n",
      "Indice 30 : Comitas_saldanhae_\n",
      "Indice 31 : Comitas_stolida_\n",
      "Indice 32 : Cosmasterias_felipes_\n",
      "Indice 33 : Crossaster_penicillatus_\n",
      "Indice 34 : Cypraeovula_iutsui_\n",
      "Indice 35 : Diplopteraster_multipes_\n",
      "Indice 36 : Dipsacaster_sladeni_capensis_\n",
      "Indice 37 : Echinus_gilchristi_\n",
      "Indice 38 : Eleutherobia_variable_\n",
      "Indice 39 : Euspira_napus_\n",
      "Indice 40 : Exodromidia_spinosa_\n",
      "Indice 41 : Exodromidia_spinosissima_\n",
      "Indice 42 : Flabellum_(Ulocyathus)_messum_\n",
      "Indice 43 : Funchalia_woodwardi_\n",
      "Indice 44 : Fusinus_africanae_\n",
      "Indice 45 : Fusinus_hayesi_\n",
      "Indice 46 : Fusitriton_magellanicus_\n",
      "Indice 47 : Fusivoluta_pyrrhostoma_\n",
      "Indice 48 : Glyphocrangon_spp_\n",
      "Indice 49 : Goneplax_clevai_\n",
      "Indice 50 : Granulifusus_rubrolineatus_\n",
      "Indice 51 : Gynandrocarpa_placenta_\n",
      "Indice 52 : Halcurias_capensis_\n",
      "Indice 53 : Haliporoides_triarthrus_\n",
      "Indice 54 : Hemiocnus_insolens_\n",
      "Indice 55 : Henricia_abyssalis_\n",
      "Indice 56 : Hermit_crab_\n",
      "Indice 57 : Hippasteria_phrygiana_\n",
      "Indice 58 : Holothuroidea_\n",
      "Indice 59 : Hydrozoa_spp_\n",
      "Indice 60 : Inachidae_\n",
      "Indice 61 : Isididae_\n",
      "Indice 62 : Isopods_\n",
      "Indice 63 : Kaloplocamus_ramosus_\n",
      "Indice 64 : Lamellaria_Coriocella_spp_\n",
      "Indice 65 : Limopsis_chuni_\n",
      "Indice 66 : Lithodes_ferox_\n",
      "Indice 67 : Lophaster_quadrispinus_\n",
      "Indice 68 : Luidia_sarsii_africana_\n",
      "Indice 69 : Marginella_musica_\n",
      "Indice 70 : Marthasterias_africana_\n",
      "Indice 71 : Mediaster_bairdi_capensis_\n",
      "Indice 72 : Merhippolyte_agulhasensis_\n",
      "Indice 73 : Miersiograpsus_kingsleyi_\n",
      "Indice 74 : Munida_benguela_\n",
      "Indice 75 : Mursia_cristiata_\n",
      "Indice 76 : Mycale_anisochela_\n",
      "Indice 77 : Nassarius speciosus_\n",
      "Indice 78 : Nassarius_vinctus_\n",
      "Indice 79 : Neolithodes_asperrimus_\n",
      "Indice 80 : Neopilumnoplax_heterochir_\n",
      "Indice 81 : Neptuneopsis_gilchristi_\n",
      "Indice 82 : Nudibranchia_\n",
      "Indice 83 : Ophiomyxa_vivipara_capensis_\n",
      "Indice 84 : Ophiothrix_aristulata_\n",
      "Indice 85 : Ophiothrix_fragilis_\n",
      "Indice 86 : Ophiothrix_spp_\n",
      "Indice 87 : Ophiura_costata_costata_\n",
      "Indice 88 : Ophiura_trimeni_\n",
      "Indice 89 : Pagurus_cuanensis_\n",
      "Indice 90 : Parapagurus_bouvieri_\n",
      "Indice 91 : Pasiphaea_sp._1_\n",
      "Indice 92 : Pasiphaea_sp._2_\n",
      "Indice 93 : Pecten_sulcicostatus_\n",
      "Indice 94 : Pelagia_noctiluca_\n",
      "Indice 95 : Perissasterias_polyacantha_\n",
      "Indice 96 : Philine_aperta_\n",
      "Indice 97 : Philinopsis_capensis_\n",
      "Indice 98 : Phormosoma_placenta_africana_\n",
      "Indice 99 : Plesionika_martia_\n",
      "Indice 100 : Pleurobranchaea_bubala_\n",
      "Indice 101 : Polychaete_tubes_(only)_\n",
      "Indice 102 : Polychaete_worms_\n",
      "Indice 103 : Polyechinus_agulhensis_\n",
      "Indice 104 : Poraniopsis_echinaster_\n",
      "Indice 105 : Porifera_\n",
      "Indice 106 : Prawns_\n",
      "Indice 107 : Projasus_parkeri_\n",
      "Indice 108 : Pseudarchaster_brachyactis_\n",
      "Indice 109 : Pseudarchaster_tessellatus_\n",
      "Indice 110 : Pseudodromia_rotunda_\n",
      "Indice 111 : Pseudodromia_spp__\n",
      "Indice 112 : Pseudostichopus_langeae_\n",
      "Indice 113 : Psilaster_acuminatus_\n",
      "Indice 114 : Pteraster_capensis_\n",
      "Indice 115 : Pterygosquilla_capensis_\n",
      "Indice 116 : Pycnogonid_spp__\n",
      "Indice 117 : Pyromaia_tuberculata_\n",
      "Indice 118 : Rochinia_hertwigi_\n",
      "Indice 119 : Rossella_antarctica_\n",
      "Indice 120 : Salpa_spp__\n",
      "Indice 121 : Scaphander_punctostriatus_\n",
      "Indice 122 : Scleractinia_\n",
      "Indice 123 : Sclerasterias_spp_\n",
      "Indice 124 : Seafan_\n",
      "Indice 125 : Solenocera_africana_\n",
      "Indice 126 : Spatangus_capensis_\n",
      "Indice 127 : Stereomastis_sculpta_\n",
      "Indice 128 : Stylasteridae_\n",
      "Indice 129 : Suberites_dandelenae_\n",
      "Indice 130 : Sympagurus_dimorphus_\n",
      "Indice 131 : Synallactes_viridilimus_\n",
      "Indice 132 : Terebratulina_sp__\n",
      "Indice 133 : Toraster_tuberculatus_\n",
      "Indice 134 : Triviella_spp__\n",
      "Indice 135 : Turritella_declivis_\n",
      "Indice 136 : Vitjazmaia_latidactyla_\n"
     ]
    }
   ],
   "source": [
    "# Récupérer les noms des classes\n",
    "class_names = train_generator.class_indices\n",
    "class_names = {v: k for k, v in class_names.items()}  # Inverser le dictionnaire pour obtenir les noms des classes\n",
    "\n",
    "# Affichage des noms des classes \n",
    "print(\"Classes et indices correspondants :\")\n",
    "for idx, class_name in class_names.items():\n",
    "    print(f\"Indice {idx} : {class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2a5278c-7e8d-48c0-b484-2e38bd5b72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin du dataset\n",
    "data_dir = r'C:\\Users\\Christian\\Desktop\\UE Projet\\Dataset\\train_data'\n",
    "\n",
    "# Préparer les transformations et le DataLoader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(), # Ici on normalise les images en les fesant passer de la plage [0,255] en la plage [0,1] car initialement les images sont des tenseurs numpy\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalisation appliqué au format des couleurs RGB pour une moyenne de mean et un ecart type de std\n",
    "]) # On aurait pu ajouter d'autre transformation mais ca serait une redondance car cela a deja été fait dans notre section data augmentation.\n",
    "\n",
    "# Application de ce second prétraitement aux données de la base train_data\n",
    "train_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Charger le modèle ViT pré-entraîné depuis timm avec 137 sorties correspondant au 137 classes\n",
    "model = create_model('vit_base_patch16_224', pretrained=True)\n",
    "model.head = nn.Linear(model.head.in_features, 137)\n",
    "\n",
    "# Définir l'optimiseur et la fonction de perte\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5876a552-7dfc-47a3-931c-7efd6ba71156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1150, Train Accuracy: 93.99%, Time: 9689.41 seconds\n",
      "Epoch [2/10], Loss: 0.0107, Train Accuracy: 96.01%, Time: 289364.29 seconds\n",
      "Epoch [3/10], Loss: 0.0005, Train Accuracy: 98.23%, Time: 3876.70 seconds\n",
      "Epoch [4/10], Loss: 0.0725, Train Accuracy: 97.94%, Time: 5188.05 seconds\n",
      "Epoch [5/10], Loss: 0.0003, Train Accuracy: 99.45%, Time: 4061.54 seconds\n"
     ]
    }
   ],
   "source": [
    "# Entrainement du model avec affichage de la précision et de la perte\n",
    "for epoch in range(5):  \n",
    "    start_time = time.time() # Début de l'époque\n",
    "    correct_train = 0 # Nombre total d'image correctement predit dans cette epoque\n",
    "    total_train = 0 # Nombre total d'image vu dans cette epoque\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad() # Reinitialisation des gradients\n",
    "        outputs = model(images) # Predictions\n",
    "        loss = criterion(outputs, labels) # Loss\n",
    "        loss.backward() # Retropropagation\n",
    "        optimizer.step() # Ajustement des parametres\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1) # On reccupere l'indice de la classe predite avec la plus grande probabilité\n",
    "        total_train += labels.size(0) # Mise a jour du nombre d'image vu dans cette epoque jusqu'a cette etapes\n",
    "        correct_train += (predicted == labels).sum().item() # Mise a jour du Nombre total d'image correctement predit dans cette epoque\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train # Calcul de la precision apres chaque etapes\n",
    "    end_time = time.time() # Fin de l'époque \n",
    "    epoch_time = end_time - start_time # Calcul du temps d'exécution \n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}%, Time: {epoch_time:.2f} seconds\")\n",
    "    #print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}%\") # affichage de l'epoque, de la perte et de la precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20f7d4a5-3481-4809-810b-f096f61b204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22bd97c1-9e1d-480f-9306-dfca7b2c21a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "with open(\"class_indices.json\", \"w\") as f:\n",
    "    json.dump(class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e167c-373a-4740-a9ae-7dab0c6158de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
